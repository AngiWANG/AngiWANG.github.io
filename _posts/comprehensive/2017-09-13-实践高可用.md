---
layout: post
title: "实践高可用"
date: 2017-08-30 17:08:00 +0800
categories: 综合
tags: ELK comprehensive elasticsearch logstack kibana
---

[Elastic](https://www.elastic.co/), The Open Source Elastic Stack, Reliably and securely take data from any source, in any format, and search, analyze, and visualize it in real time.

## ElasticSearch

[ElasticSearch](https://www.elastic.co/products/elasticsearch)

```shell
$ elasticsearch -d
```

http://localhost:9200/

## Logstash

[Logstash](https://www.elastic.co/cn/products/logstash)

[Logstash Docs](https://www.elastic.co/guide/en/logstash/current/index.html)

```shell
angi@angi-deepin:~/software/logstash/bin$ ./logstash -e 'input { stdin { } } output { stdout {} }'
ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console.
Sending Logstash's logs to /home/angi/software/logstash/logs which is now configured via log4j2.properties
[2017-09-06T17:02:22,327][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.queue", :path=>"/home/angi/software/logstash/data/queue"}
[2017-09-06T17:02:22,331][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.dead_letter_queue", :path=>"/home/angi/software/logstash/data/dead_letter_queue"}
[2017-09-06T17:02:22,351][INFO ][logstash.agent           ] No persistent UUID file found. Generating new UUID {:uuid=>"d155f460-9782-44f7-87ad-862018780cec", :path=>"/home/angi/software/logstash/data/uuid"}
[2017-09-06T17:02:22,479][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>1000}
[2017-09-06T17:02:22,519][INFO ][logstash.pipeline        ] Pipeline main started
The stdin plugin is now waiting for input:
[2017-09-06T17:02:22,594][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
# 人工输入hello world
hello world
2017-09-06T09:02:44.383Z angi-deepin hello world
```

logstash.conf

```
input {
  beats {
    port => 5044
  }
}

# The filter part of this file is commented out to indicate that it is
# optional.
# filter {
#
# }

output {
  elasticsearch {
    hosts => "localhost:9200"
    manage_template => false
    index => "%{[@metadata][beat]}-%{+YYYY.MM.dd}" 
    document_type => "%{[@metadata][type]}" 
  }
}
```

```shell
$ logstash -f ../config/logstash.conf
```



### input

[log4j plugin](https://www.elastic.co/guide/en/logstash/current/plugins-inputs-log4j.html)不被推荐，使用[filebeat](https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-installation.html)替换

### filter

### output

## Beats

[Beats](https://www.elastic.co/products/beats)

[Beats Docs](https://www.elastic.co/guide/en/beats/libbeat/current/index.html)

### Filebeat

轻量型日志采集器，当您要面对成百上千、甚至成千上万的服务器、虚拟机和容器生成的日志时，请告别 SSH 吧。Filebeat 将为您提供一种轻量型方法，用于转发和汇总日志与文件，让简单的事情不再繁杂。

[Filebeat Docs](https://www.elastic.co/guide/en/beats/filebeat/current/index.html)

filebeat.yml

```yaml
filebeat.prospectors:
- input_type: log
  paths:
    - /var/log/*.log
output.elasticsearch:
  hosts: ["192.168.1.42:9200"]
output.logstash:
  hosts: ["127.0.0.1:5044"]
```

```shell
$ ./import_dashboards -only-index
Created temporary directory /tmp/tmp566769272
Downloading https://artifacts.elastic.co/downloads/beats/beats-dashboards/beats-dashboards-5.5.2.zip
Unzip archive /tmp/tmp566769272
Importing Kibana from /tmp/tmp566769272/beats-dashboards-5.5.2/filebeat
Import directory /tmp/tmp566769272/beats-dashboards-5.5.2/filebeat/index-pattern
Import index to /.kibana/index-pattern/filebeat-* from /tmp/tmp566769272/beats-dashboards-5.5.2/filebeat/index-pattern/filebeat.json

Importing Kibana from /tmp/tmp566769272/beats-dashboards-5.5.2/heartbeat
Importing Kibana from /tmp/tmp566769272/beats-dashboards-5.5.2/metricbeat
Importing Kibana from /tmp/tmp566769272/beats-dashboards-5.5.2/packetbeat
Importing Kibana from /tmp/tmp566769272/beats-dashboards-5.5.2/winlogbeat 
```

```shell
$ filebeat start
```



### Metricbeat

[Metricbeat](https://www.elastic.co/cn/products/beats/metricbeat)，轻量型指标采集器，用于从系统和服务收集指标。从 CPU 到内存，从 Redis 到 Nginx，Metricbeat 能够以一种轻量型的方式，输送各种系统和服务统计数据。

[Metricbeat Docs](https://www.elastic.co/guide/en/beats/metricbeat/current/index.html)

### Packetbeat

[Packetbeat](https://www.elastic.co/cn/products/beats/packetbeat)，轻量型网络数据采集器，用于深挖网线上传输的数据，了解应用程序动态。Packetbeat 是一款轻量型网络数据包分析器，能够将数据发送至 Logstash 或 Elasticsearch。

[Packetbeat Docs](https://www.elastic.co/guide/en/beats/packetbeat/current/index.html)

### Winlogbeat

轻量型 Windows 事件日志采集器，用于密切监控基于 Windows 的基础架构上发生的事件。Winlogbeat 能够以一种轻量型的方式，将 Windows 事件日志实时地流式传输至 Elasticsearch 和 Logstash。

### Heartbeat

[Heartbeat](https://www.elastic.co/cn/products/beats/heartbeat)，轻量型运行时间监控采集器，通过主动探测来监控服务可用性。Heartbeat 面对一系列 URL 时会问这个简单的问题：你还活着吗？Heartbeat 会将这些信息和响应时间输送至 Elastic Stack 的其他部分，以做进一步分析。

[Heartbeat Docs](https://www.elastic.co/guide/en/beats/heartbeat/current/index.html)

## Kibana

[Kibana](https://www.elastic.co/products/kibana)

```shell
$ kibana
```

http://localhost:5601

## X-Pack

